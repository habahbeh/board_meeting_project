# audio_processing/tasks_enhanced.py - Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù†Ø© Ù…Ø¹ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ØµÙˆØªÙŠØ©

import os
import tempfile
import time
from django.conf import settings
from django.utils.translation import gettext as _
from transcription.models import Meeting, TranscriptSegment, MeetingReport
from speaker_identification.models import Speaker
from audio_processing.utils.preprocessing import convert_audio_to_wav, enhance_audio_quality
from transcription.utils.whisper_gpt4o import transcribe_with_whisper
import logging
import openai

logger = logging.getLogger(__name__)

# ØªÙƒÙˆÙŠÙ† OpenAI
if hasattr(settings, 'OPENAI_API_KEY') and settings.OPENAI_API_KEY:
    openai.api_key = settings.OPENAI_API_KEY


def process_meeting_task(meeting_id):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ - Ù†Ù‚Ø·Ø© Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    meeting = Meeting.objects.get(id=meeting_id)

    try:
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
        use_voice_comparison = getattr(settings, 'USE_VOICE_COMPARISON', False)

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆÙØ± Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ØµÙˆØªÙŠØ©
        if use_voice_comparison and os.getenv("HUGGINGFACE_TOKEN"):
            logger.info(f"Processing meeting {meeting_id} with voice comparison")
            process_meeting_with_voice_comparison(meeting)
        elif settings.OPENAI_API_KEY and not getattr(settings, 'TESTING_MODE', False):
            logger.info(f"Processing meeting {meeting_id} with OpenAI")
            process_meeting_with_openai(meeting)
        else:
            logger.info(f"Processing meeting {meeting_id} in test mode")
            process_meeting_test_mode(meeting)

    except Exception as e:
        logger.error(f"Error processing meeting {meeting_id}: {str(e)}")
        meeting.processed = False
        meeting.save()
        raise e


def process_meeting_with_voice_comparison(meeting):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¹ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ØµÙˆØªÙŠØ©"""
    print(f"ğŸ¤ Voice Comparison Processing for meeting {meeting.id}")

    try:
        # Ø§Ø³ØªÙŠØ±Ø§Ø¯ ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ØµÙˆØªÙŠØ©
        from speaker_identification.utils.voice_comparison import (
            process_meeting_with_diarization,
            save_speaker_embedding
        )

        # 1. ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ØµÙ…Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ© Ù„Ù„Ù…ØªØ­Ø¯Ø«ÙŠÙ†
        prepare_speaker_embeddings()

        # 2. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª Ù…Ø¹ diarization
        audio_path = meeting.audio_file.path
        segments = process_meeting_with_diarization(audio_path)

        if not segments:
            raise Exception("No segments found from diarization")

        print(f"âœ… Found {len(segments)} segments")

        # 3. Ù†Ø³Ø® Ø§Ù„ØµÙˆØª Ø¨Ù€ Whisper
        with open(audio_path, "rb") as audio_file:
            transcript = openai.Audio.transcribe(
                model="whisper-1",
                file=audio_file,
                language="ar"
            )

        # 4. Ø¯Ù…Ø¬ Ø§Ù„Ù†Øµ Ù…Ø¹ Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„Ù…ØªØ­Ø¯Ø«ÙŠÙ†
        merged_segments = merge_transcript_with_diarization(
            transcript['text'],
            segments
        )

        # 5. Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        save_segments_to_database(meeting, merged_segments)

        # 6. Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        create_meeting_report_from_segments(meeting, merged_segments)

        # 7. ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹
        meeting.processed = True
        meeting.save()

        print(f"âœ… Meeting {meeting.id} processed successfully with voice comparison!")

    except ImportError as e:
        logger.error(f"Voice comparison modules not available: {str(e)}")
        logger.info("Falling back to OpenAI processing")
        process_meeting_with_openai(meeting)
    except Exception as e:
        logger.error(f"Voice comparison error: {str(e)}")
        logger.info("Falling back to OpenAI processing")
        process_meeting_with_openai(meeting)


def process_meeting_with_openai(meeting):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø­Ù‚ÙŠÙ‚ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenAI"""
    print(f"Starting OpenAI processing for meeting {meeting.id}")

    temp_dir = tempfile.mkdtemp()

    try:
        # 1. ØªØ­Ø¶ÙŠØ± Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ
        audio_path = os.path.join(settings.MEDIA_ROOT, str(meeting.audio_file))
        print(f"Audio file: {audio_path}")

        # 2. Ù†Ø³Ø® Ø§Ù„ØµÙˆØª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Whisper
        print("Transcribing with Whisper...")
        with open(audio_path, "rb") as audio_file:
            transcript = openai.Audio.transcribe(
                model="whisper-1",
                file=audio_file,
                language="ar",
                response_format="text"
            )

        print(f"Transcription complete. Length: {len(transcript)} characters")

        # 3. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ ÙˆØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ØªØ­Ø¯Ø«ÙŠÙ† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… GPT
        print("Analyzing transcript with GPT...")

        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡ ØµØºÙŠØ±Ø© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
        segments = split_text_into_segments(transcript)
        print(f"Split into {len(segments)} segments")

        # Ø¬Ù„Ø¨ Ø§Ù„Ù…ØªØ­Ø¯Ø«ÙŠÙ† Ø§Ù„Ù…Ø­ØªÙ…Ù„ÙŠÙ†
        speakers = Speaker.objects.all()
        speaker_info = "\n".join([f"- {s.name} ({s.position})" for s in speakers])

        # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ„ Ù…Ù‚Ø·Ø¹
        processed_segments = []
        current_speaker = None

        for i, segment_text in enumerate(segments):
            print(f"Processing segment {i + 1}/{len(segments)}")

            # Ø§Ø³ØªØ®Ø¯Ø§Ù… GPT Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ØªØ­Ø¯Ø«
            prompt = f"""
            Ù„Ø¯ÙŠÙƒ Ù‡Ø°Ù‡ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† Ø§Ù„Ù…ØªØ­Ø¯Ø«ÙŠÙ† Ø§Ù„Ù…Ø­ØªÙ…Ù„ÙŠÙ†:
            {speaker_info}

            Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ Ù…Ù† Ø§Ø¬ØªÙ…Ø§Ø¹. Ø­Ø¯Ø¯ Ù…Ù† Ø§Ù„Ù…ØªØ­Ø¯Ø«:
            "{segment_text}"

            Ø§Ø¨Ø­Ø« Ø¹Ù†:
            1. Ø¹Ø¨Ø§Ø±Ø§Øª ØªØ¹Ø±ÙŠÙ (Ø£Ù†Ø§ ÙÙ„Ø§Ù†ØŒ Ù…Ø¹ÙƒÙ… ÙÙ„Ø§Ù†)
            2. Ø°ÙƒØ± Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ (Ø´ÙƒØ±Ø§Ù‹ Ø¯ÙƒØªÙˆØ± Ø£Ø­Ù…Ø¯)
            3. ØªØºÙŠÙŠØ± Ø§Ù„Ù…ØªØ­Ø¯Ø« (Ø£Ø¹Ø·ÙŠ Ø§Ù„ÙƒÙ„Ù…Ø© Ù„Ù€)

            Ø£Ø¬Ø¨ ÙÙ‚Ø· Ø¨Ø§Ø³Ù… Ø§Ù„Ù…ØªØ­Ø¯Ø« Ø£Ùˆ "ØºÙŠØ± Ù…Ø­Ø¯Ø¯" Ø¥Ø°Ø§ Ù„Ù… ØªØ³ØªØ·Ø¹ Ø§Ù„ØªØ­Ø¯ÙŠØ¯.
            """

            try:
                response = openai.ChatCompletion.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ù…Ø­Ø§Ø¶Ø± Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹Ø§Øª"},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=50,
                    temperature=0.3
                )

                speaker_name = response.choices[0].message.content.strip()
                print(f"GPT identified speaker: {speaker_name}")

                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…ØªØ­Ø¯Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                speaker_obj = None
                for s in speakers:
                    if s.name in speaker_name or speaker_name in s.name:
                        speaker_obj = s
                        current_speaker = s
                        break

                if not speaker_obj:
                    if current_speaker:
                        speaker_obj = current_speaker
                    else:
                        speaker_obj = Speaker.objects.get_or_create(
                            name="Ù…ØªØ­Ø¯Ø« ØºÙŠØ± Ù…Ø­Ø¯Ø¯",
                            defaults={'position': 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯', 'speaker_type': 'unknown'}
                        )[0]

            except Exception as e:
                print(f"GPT error: {e}")
                speaker_obj = current_speaker or Speaker.objects.get_or_create(
                    name="Ù…ØªØ­Ø¯Ø« ØºÙŠØ± Ù…Ø­Ø¯Ø¯",
                    defaults={'position': 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯', 'speaker_type': 'unknown'}
                )[0]

            # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù‚Ø·Ø¹
            is_decision = any(word in segment_text for word in ['Ø§Ù„Ù‚Ø±Ø§Ø±', 'Ù†Ù‚Ø±Ø±', 'Ø§Ù„Ù…ÙˆØ§ÙÙ‚Ø© Ø¹Ù„Ù‰', 'ØªÙ‚Ø±Ø±'])
            is_task = any(word in segment_text for word in ['Ù…Ù‡Ù…Ø©', 'Ù†ÙƒÙ„Ù', 'ÙŠØ¬Ø¨ Ø¹Ù„Ù‰', 'ØªÙƒÙ„ÙŠÙ'])

            processed_segments.append({
                'speaker': speaker_obj,
                'text': segment_text,
                'is_decision': is_decision,
                'is_task': is_task,
                'start_time': i * 30,  # ØªÙ‚Ø¯ÙŠØ± Ø§Ù„ÙˆÙ‚Øª
                'end_time': (i + 1) * 30
            })

        # 4. Ø­ÙØ¸ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        print("Saving segments to database...")
        for seg in processed_segments:
            TranscriptSegment.objects.create(
                meeting=meeting,
                speaker=seg['speaker'],
                text=seg['text'],
                start_time=seg['start_time'],
                end_time=seg['end_time'],
                confidence=0.85,
                is_decision=seg['is_decision'],
                is_action_item=seg['is_task']
            )

        # 5. Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        print("Creating meeting report...")
        create_meeting_report(meeting, processed_segments)

        # 6. ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
        meeting.processed = True
        meeting.save()
        print(f"Meeting {meeting.id} processed successfully!")

    except Exception as e:
        logger.error(f"Error: {str(e)}")
        raise
    finally:
        import shutil
        shutil.rmtree(temp_dir, ignore_errors=True)


def process_meeting_test_mode(meeting):
    """ÙˆØ¶Ø¹ ØªØ¬Ø±ÙŠØ¨ÙŠ Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ø¶Ø­Ø©"""
    print(f"Test mode for meeting {meeting.id}")

    # Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ© ÙˆØ§Ø¶Ø­Ø©
    test_data = [
        ("Ø¯. Ø£Ø­Ù…Ø¯ Ù…Ø­Ù…Ø¯", "Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…ØŒ Ø£Ù†Ø§ Ø§Ù„Ø¯ÙƒØªÙˆØ± Ø£Ø­Ù…Ø¯ Ù…Ø­Ù…Ø¯ Ø±Ø¦ÙŠØ³ Ù…Ø¬Ù„Ø³ Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©. Ù†Ø¨Ø¯Ø£ Ø§Ø¬ØªÙ…Ø§Ø¹Ù†Ø§ Ø§Ù„ÙŠÙˆÙ….", False, False),
        ("Ø¯. Ø£Ø­Ù…Ø¯ Ù…Ø­Ù…Ø¯", "Ø¬Ø¯ÙˆÙ„ Ø£Ø¹Ù…Ø§Ù„Ù†Ø§ ÙŠØªØ¶Ù…Ù† Ù…Ù†Ø§Ù‚Ø´Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø§Ù„ÙŠØ© ÙˆØ®Ø·Ø· Ø§Ù„ØªÙˆØ³Ø¹.", False, False),
        ("Ø£. Ø³Ø§Ø±Ø© Ø®Ø§Ù„Ø¯", "Ø´ÙƒØ±Ø§Ù‹ Ø¯ÙƒØªÙˆØ± Ø£Ø­Ù…Ø¯. Ø£Ù†Ø§ Ø³Ø§Ø±Ø© Ø®Ø§Ù„Ø¯ Ø§Ù„Ù…Ø¯ÙŠØ± Ø§Ù„Ù…Ø§Ù„ÙŠ. Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø§Ù„ÙŠØ© Ù…Ù…ØªØ§Ø²Ø© Ù‡Ø°Ø§ Ø§Ù„Ø±Ø¨Ø¹.", False,
         False),
        ("Ø£. Ø³Ø§Ø±Ø© Ø®Ø§Ù„Ø¯", "Ø­Ù‚Ù‚Ù†Ø§ Ù†Ù…ÙˆØ§Ù‹ Ø¨Ù†Ø³Ø¨Ø© 15% Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø§Ù„Ø±Ø¨Ø¹ Ø§Ù„Ø³Ø§Ø¨Ù‚.", False, False),
        ("Ù…. ÙØ§Ø·Ù…Ø© Ø¹Ù„ÙŠ", "Ø£Ù†Ø§ ÙØ§Ø·Ù…Ø© Ø¹Ù„ÙŠ Ø§Ù„Ù…Ø¯ÙŠØ± Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ. Ø£Ù‚ØªØ±Ø­ Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø§Ø³ØªØ«Ù…Ø§Ø± ÙÙŠ Ø§Ù„ØªØ³ÙˆÙŠÙ‚.", False, False),
        ("Ø¯. Ø£Ø­Ù…Ø¯ Ù…Ø­Ù…Ø¯", "Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ø£ÙˆÙ„: Ø§Ù„Ù…ÙˆØ§ÙÙ‚Ø© Ø¹Ù„Ù‰ Ø²ÙŠØ§Ø¯Ø© Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ø§Ù„ØªØ³ÙˆÙŠÙ‚ Ø¨Ù†Ø³Ø¨Ø© 10%.", True, False),
        ("Ø¯. Ø£Ø­Ù…Ø¯ Ù…Ø­Ù…Ø¯", "Ù…Ù‡Ù…Ø© Ù„Ø³Ø§Ø±Ø©: Ø¥Ø¹Ø¯Ø§Ø¯ Ø®Ø·Ø© ØªÙØµÙŠÙ„ÙŠØ© Ù„Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø®Ù„Ø§Ù„ Ø£Ø³Ø¨ÙˆØ¹.", False, True),
        ("Ø£. Ø³Ø§Ø±Ø© Ø®Ø§Ù„Ø¯", "ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø§Ù„Ù…Ù‡Ù…Ø© ÙˆØ³Ø£Ù†ÙØ°Ù‡Ø§ ÙÙŠ Ø§Ù„Ù…ÙˆØ¹Ø¯ Ø§Ù„Ù…Ø­Ø¯Ø¯.", False, False),
    ]

    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ØªØ­Ø¯Ø«ÙŠÙ†
    speakers = {}
    speakers_data = [
        ("Ø¯. Ø£Ø­Ù…Ø¯ Ù…Ø­Ù…Ø¯", "Ø±Ø¦ÙŠØ³ Ù…Ø¬Ù„Ø³ Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©", "board"),
        ("Ø£. Ø³Ø§Ø±Ø© Ø®Ø§Ù„Ø¯", "Ø§Ù„Ù…Ø¯ÙŠØ± Ø§Ù„Ù…Ø§Ù„ÙŠ", "executive"),
        ("Ù…. ÙØ§Ø·Ù…Ø© Ø¹Ù„ÙŠ", "Ø§Ù„Ù…Ø¯ÙŠØ± Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ", "executive"),
    ]

    for name, position, type_ in speakers_data:
        speaker, _ = Speaker.objects.get_or_create(
            name=name,
            defaults={'position': position, 'speaker_type': type_}
        )
        speakers[name] = speaker

    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹
    start_time = 0
    for speaker_name, text, is_decision, is_task in test_data:
        TranscriptSegment.objects.create(
            meeting=meeting,
            speaker=speakers[speaker_name],
            text=text,
            start_time=start_time,
            end_time=start_time + 20,
            confidence=0.95,
            is_decision=is_decision,
            is_action_item=is_task
        )
        start_time += 20

    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
    summary = """
    Ø§Ø¬ØªÙ…Ø§Ø¹ ØªØ¬Ø±ÙŠØ¨ÙŠ Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù†Ø¸Ø§Ù…
    Ø§Ù„Ù…Ø´Ø§Ø±ÙƒÙˆÙ†: Ø¯. Ø£Ø­Ù…Ø¯ Ù…Ø­Ù…Ø¯ØŒ Ø£. Ø³Ø§Ø±Ø© Ø®Ø§Ù„Ø¯ØŒ Ù…. ÙØ§Ø·Ù…Ø© Ø¹Ù„ÙŠ
    """

    MeetingReport.objects.create(
        meeting=meeting,
        summary=summary,
        decisions="1. Ø§Ù„Ù…ÙˆØ§ÙÙ‚Ø© Ø¹Ù„Ù‰ Ø²ÙŠØ§Ø¯Ø© Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ø§Ù„ØªØ³ÙˆÙŠÙ‚ Ø¨Ù†Ø³Ø¨Ø© 10%",
        action_items="1. Ø³Ø§Ø±Ø© Ø®Ø§Ù„Ø¯: Ø¥Ø¹Ø¯Ø§Ø¯ Ø®Ø·Ø© ØªÙØµÙŠÙ„ÙŠØ© Ù„Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø®Ù„Ø§Ù„ Ø£Ø³Ø¨ÙˆØ¹"
    )

    meeting.processed = True
    meeting.save()
    print("Test meeting processed successfully!")


def split_text_into_segments(text, segment_size=200):
    """ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ù…Ù‚Ø§Ø·Ø¹ ØµØºÙŠØ±Ø©"""
    sentences = text.split('.')
    segments = []
    current_segment = ""

    for sentence in sentences:
        if not sentence.strip():
            continue

        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ù‚Ø·Ø¹ Ø§Ù„Ø­Ø§Ù„ÙŠ ØµØºÙŠØ±Ø§Ù‹ØŒ Ø£Ø¶Ù Ø§Ù„Ø¬Ù…Ù„Ø©
        if len(current_segment) < segment_size:
            current_segment += sentence + "."
        else:
            # Ø§Ø­ÙØ¸ Ø§Ù„Ù…Ù‚Ø·Ø¹ Ø§Ù„Ø­Ø§Ù„ÙŠ ÙˆØ§Ø¨Ø¯Ø£ Ù…Ù‚Ø·Ø¹ Ø¬Ø¯ÙŠØ¯
            if current_segment:
                segments.append(current_segment.strip())
            current_segment = sentence + "."

    # Ø£Ø¶Ù Ø§Ù„Ù…Ù‚Ø·Ø¹ Ø§Ù„Ø£Ø®ÙŠØ±
    if current_segment:
        segments.append(current_segment.strip())

    return segments


def create_meeting_report(meeting, segments):
    """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹"""
    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…ØªØ­Ø¯Ø«ÙŠÙ†
    speakers_stats = {}
    for seg in segments:
        speaker_name = seg['speaker'].name
        if speaker_name not in speakers_stats:
            speakers_stats[speaker_name] = 0
        speakers_stats[speaker_name] += 1

    # Ø§Ù„Ù…Ù„Ø®Øµ
    summary = f"""
    Ø§Ø¬ØªÙ…Ø§Ø¹ Ø¨ØªØ§Ø±ÙŠØ® {meeting.date}
    Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø´Ø§Ø±ÙƒÙŠÙ†: {len(speakers_stats)}
    Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹: {len(segments)}

    Ø§Ù„Ù…Ø´Ø§Ø±ÙƒÙˆÙ†:
    """

    for speaker, count in speakers_stats.items():
        summary += f"\n- {speaker} ({count} Ù…Ø¯Ø§Ø®Ù„Ø©)"

    # Ø§Ù„Ù‚Ø±Ø§Ø±Ø§Øª
    decisions = [seg for seg in segments if seg['is_decision']]
    decisions_text = ""
    for i, dec in enumerate(decisions, 1):
        decisions_text += f"{i}. {dec['speaker'].name}: {dec['text']}\n"

    # Ø§Ù„Ù…Ù‡Ø§Ù…
    tasks = [seg for seg in segments if seg['is_task']]
    tasks_text = ""
    for i, task in enumerate(tasks, 1):
        tasks_text += f"{i}. {task['speaker'].name}: {task['text']}\n"

    MeetingReport.objects.create(
        meeting=meeting,
        summary=summary.strip(),
        decisions=decisions_text.strip() or "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù‚Ø±Ø§Ø±Ø§Øª",
        action_items=tasks_text.strip() or "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù‡Ø§Ù…"
    )


def prepare_speaker_embeddings():
    """ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ØµÙ…Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ© Ù„Ù„Ù…ØªØ­Ø¯Ø«ÙŠÙ†"""
    try:
        from speaker_identification.utils.voice_comparison import save_speaker_embedding

        speakers = Speaker.objects.filter(reference_audio__isnull=False)

        for speaker in speakers:
            if not speaker.voice_embedding:
                try:
                    save_speaker_embedding(speaker)
                    logger.info(f"Prepared embedding for {speaker.name}")
                except Exception as e:
                    logger.warning(f"Failed to prepare embedding for {speaker.name}: {e}")
    except ImportError:
        logger.warning("Voice comparison module not available")


def merge_transcript_with_diarization(transcript_text, diarization_segments):
    """Ø¯Ù…Ø¬ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù†Ø³ÙˆØ® Ù…Ø¹ Ù…Ù‚Ø§Ø·Ø¹ diarization"""

    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø¬Ù…Ù„
    sentences = [s.strip() + '.' for s in transcript_text.split('.') if s.strip()]

    # ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¬Ù…Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹
    merged = []
    sentence_idx = 0

    for segment in diarization_segments:
        segment_duration = segment['end'] - segment['start']
        segment_text = ""

        # ØªÙ‚Ø¯ÙŠØ± Ø¹Ø¯Ø¯ Ø§Ù„Ø¬Ù…Ù„ Ù„Ù‡Ø°Ø§ Ø§Ù„Ù…Ù‚Ø·Ø¹
        while sentence_idx < len(sentences) and len(segment_text) < segment_duration * 20:
            segment_text += sentences[sentence_idx] + " "
            sentence_idx += 1

        if segment_text.strip():
            # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù‚Ø·Ø¹
            is_decision = any(word in segment_text for word in ['Ø§Ù„Ù‚Ø±Ø§Ø±', 'Ù†Ù‚Ø±Ø±', 'Ø§Ù„Ù…ÙˆØ§ÙÙ‚Ø©'])
            is_task = any(word in segment_text for word in ['Ù…Ù‡Ù…Ø©', 'Ù†ÙƒÙ„Ù', 'ÙŠØ¬Ø¨ Ø¹Ù„Ù‰'])

            merged.append({
                'speaker': segment['speaker'],
                'text': segment_text.strip(),
                'start': segment['start'],
                'end': segment['end'],
                'is_decision': is_decision,
                'is_task': is_task
            })

    return merged


def save_segments_to_database(meeting, segments):
    """Ø­ÙØ¸ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    # Ø­Ø°Ù Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
    TranscriptSegment.objects.filter(meeting=meeting).delete()

    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
    for seg in segments:
        TranscriptSegment.objects.create(
            meeting=meeting,
            speaker=seg['speaker'],
            text=seg['text'],
            start_time=seg['start'],
            end_time=seg['end'],
            confidence=0.85,
            is_decision=seg.get('is_decision', False),
            is_action_item=seg.get('is_task', False)
        )


def create_meeting_report_from_segments(meeting, segments):
    """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ù…Ù† Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„Ù…Ø¯Ù…Ø¬Ø©"""
    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…ØªØ­Ø¯Ø«ÙŠÙ†
    speaker_stats = {}
    for seg in segments:
        name = seg['speaker'].name
        if name not in speaker_stats:
            speaker_stats[name] = {
                'count': 0,
                'duration': 0
            }
        speaker_stats[name]['count'] += 1
        speaker_stats[name]['duration'] += seg['end'] - seg['start']

    summary = f"""
Ø§Ø¬ØªÙ…Ø§Ø¹: {meeting.title}
Ø§Ù„ØªØ§Ø±ÙŠØ®: {meeting.date}
Ø¹Ø¯Ø¯ Ø§Ù„Ù…ØªØ­Ø¯Ø«ÙŠÙ†: {len(speaker_stats)}
Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹: {len(segments)}

Ø§Ù„Ù…ØªØ­Ø¯Ø«ÙˆÙ† (Ø­Ø³Ø¨ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ØµÙˆØªÙŠØ©):
"""
    for name, stats in speaker_stats.items():
        duration_min = stats['duration'] / 60
        summary += f"\n- {name}: {stats['count']} Ù…Ø¯Ø§Ø®Ù„Ø© ({duration_min:.1f} Ø¯Ù‚ÙŠÙ‚Ø©)"

    # Ø§Ù„Ù‚Ø±Ø§Ø±Ø§Øª ÙˆØ§Ù„Ù…Ù‡Ø§Ù…
    decisions = []
    tasks = []

    for seg in segments:
        if seg.get('is_decision'):
            decisions.append(f"{seg['speaker'].name}: {seg['text']}")
        if seg.get('is_task'):
            tasks.append(f"{seg['speaker'].name}: {seg['text']}")

    # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
    MeetingReport.objects.filter(meeting=meeting).delete()
    MeetingReport.objects.create(
        meeting=meeting,
        summary=summary.strip(),
        decisions="\n".join(decisions) or "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù‚Ø±Ø§Ø±Ø§Øª",
        action_items="\n".join(tasks) or "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù‡Ø§Ù…"
    )