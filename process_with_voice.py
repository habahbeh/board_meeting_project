# process_with_voice.py - Ù…Ø¹Ø§Ù„Ø¬ Ø±Ø¦ÙŠØ³ÙŠ Ù…Ø¹ Ù…Ù‚Ø§Ø±Ù†Ø© ØµÙˆØªÙŠØ©

import os
import django

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'board_meeting_project.settings')
django.setup()

from django.conf import settings
from transcription.models import Meeting, TranscriptSegment, MeetingReport
from speaker_identification.models import Speaker
from speaker_identification.utils.voice_comparison import (
    process_meeting_with_diarization,
    save_speaker_embedding,
    get_embedding_model,
    get_diarization_pipeline
)
import openai
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ØªÙƒÙˆÙŠÙ† OpenAI
openai.api_key = settings.OPENAI_API_KEY


def prepare_speakers():
    """ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ØµÙ…Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ© Ù„Ù„Ù…ØªØ­Ø¯Ø«ÙŠÙ†"""
    print("\nğŸ¤ Preparing speaker embeddings...")

    speakers = Speaker.objects.filter(reference_audio__isnull=False)
    prepared = 0

    for speaker in speakers:
        if not speaker.voice_embedding:
            print(f"  Processing {speaker.name}...")
            if save_speaker_embedding(speaker):
                prepared += 1
                print(f"  âœ… {speaker.name} ready")
            else:
                print(f"  âŒ Failed for {speaker.name}")
        else:
            print(f"  âœ“ {speaker.name} already has embedding")

    print(f"\nâœ… Prepared {prepared} new embeddings")
    return speakers.count()


def process_meeting_auto(meeting_id):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ø¬ØªÙ…Ø§Ø¹ Ù…Ø¹ Ù…Ù‚Ø§Ø±Ù†Ø© ØµÙˆØªÙŠØ© ØªÙ„Ù‚Ø§Ø¦ÙŠØ©"""
    meeting = Meeting.objects.get(id=meeting_id)

    print(f"\nğŸ¯ Processing meeting: {meeting.title}")
    print(f"ğŸ“ Audio file: {meeting.audio_file.name}")

    try:
        # 1. ØªØ­Ø¶ÙŠØ± Ø§Ù„Ù…ØªØ­Ø¯Ø«ÙŠÙ†
        speaker_count = prepare_speakers()
        if speaker_count == 0:
            print("âš ï¸ Warning: No speakers with reference audio found!")

        # 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
        print("\nğŸ“Š Loading AI models...")
        get_embedding_model()
        get_diarization_pipeline()
        print("âœ… Models loaded")

        # 3. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª Ù…Ø¹ diarization
        audio_path = meeting.audio_file.path
        print(f"\nğŸ”Š Processing audio with speaker diarization...")

        segments = process_meeting_with_diarization(audio_path)

        if not segments:
            print("âŒ No segments found!")
            return

        print(f"âœ… Found {len(segments)} segments")

        # 4. Ù†Ø³Ø® Ø§Ù„ØµÙˆØª Ø¨Ù€ Whisper
        print(f"\nğŸ“ Transcribing with Whisper...")
        with open(audio_path, "rb") as audio_file:
            transcript = openai.Audio.transcribe(
                model="whisper-1",
                file=audio_file,
                language="ar"
            )

        print(f"âœ… Transcribed {len(transcript)} characters")

        # 5. Ø¯Ù…Ø¬ Ø§Ù„Ù†Øµ Ù…Ø¹ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹
        print(f"\nğŸ”— Merging transcription with speaker segments...")

        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø¬Ù…Ù„
        sentences = [s.strip() + '.' for s in transcript.split('.') if s.strip()]

        # ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¬Ù…Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„ØµÙˆØªÙŠØ©
        merged_segments = []
        sentence_idx = 0
        sentences_per_segment = max(1, len(sentences) // len(segments))

        for seg in segments:
            segment_text = ""

            # Ø¬Ù…Ø¹ Ø§Ù„Ø¬Ù…Ù„ Ù„Ù‡Ø°Ø§ Ø§Ù„Ù…Ù‚Ø·Ø¹
            for _ in range(sentences_per_segment):
                if sentence_idx < len(sentences):
                    segment_text += sentences[sentence_idx] + " "
                    sentence_idx += 1

            if segment_text.strip():
                merged_segments.append({
                    'speaker': seg['speaker'],
                    'text': segment_text.strip(),
                    'start': seg['start'],
                    'end': seg['end']
                })

        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ© Ù„Ù„Ù…Ù‚Ø·Ø¹ Ø§Ù„Ø£Ø®ÙŠØ±
        while sentence_idx < len(sentences):
            if merged_segments:
                merged_segments[-1]['text'] += " " + sentences[sentence_idx]
            sentence_idx += 1

        # 6. Ø­Ø°Ù Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
        TranscriptSegment.objects.filter(meeting=meeting).delete()

        # 7. Ø­ÙØ¸ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
        print(f"\nğŸ’¾ Saving segments to database...")

        decisions = []
        tasks = []

        for seg in merged_segments:
            # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù‚Ø·Ø¹
            is_decision = any(word in seg['text'] for word in ['Ø§Ù„Ù‚Ø±Ø§Ø±', 'Ù†Ù‚Ø±Ø±', 'Ø§Ù„Ù…ÙˆØ§ÙÙ‚Ø©', 'ØªÙ‚Ø±Ø±'])
            is_task = any(word in seg['text'] for word in ['Ù…Ù‡Ù…Ø©', 'Ù†ÙƒÙ„Ù', 'ÙŠØ¬Ø¨ Ø¹Ù„Ù‰', 'ØªÙƒÙ„ÙŠÙ'])

            if is_decision:
                decisions.append(f"{seg['speaker'].name}: {seg['text']}")
            if is_task:
                tasks.append(f"{seg['speaker'].name}: {seg['text']}")

            TranscriptSegment.objects.create(
                meeting=meeting,
                speaker=seg['speaker'],
                text=seg['text'],
                start_time=seg['start'],
                end_time=seg['end'],
                confidence=0.85,
                is_decision=is_decision,
                is_action_item=is_task
            )

        print(f"âœ… Saved {len(merged_segments)} segments")

        # 8. Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        print(f"\nğŸ“‹ Creating meeting report...")

        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…ØªØ­Ø¯Ø«ÙŠÙ†
        speaker_stats = {}
        for seg in merged_segments:
            name = seg['speaker'].name
            if name not in speaker_stats:
                speaker_stats[name] = {
                    'count': 0,
                    'duration': 0
                }
            speaker_stats[name]['count'] += 1
            speaker_stats[name]['duration'] += seg['end'] - seg['start']

        summary = f"""
Ø§Ø¬ØªÙ…Ø§Ø¹: {meeting.title}
Ø§Ù„ØªØ§Ø±ÙŠØ®: {meeting.date}
Ø¹Ø¯Ø¯ Ø§Ù„Ù…ØªØ­Ø¯Ø«ÙŠÙ†: {len(speaker_stats)}
Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹: {len(merged_segments)}

Ø§Ù„Ù…ØªØ­Ø¯Ø«ÙˆÙ† (Ø­Ø³Ø¨ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ØµÙˆØªÙŠØ©):
"""
        for name, stats in speaker_stats.items():
            duration_min = stats['duration'] / 60
            summary += f"\n- {name}: {stats['count']} Ù…Ø¯Ø§Ø®Ù„Ø© ({duration_min:.1f} Ø¯Ù‚ÙŠÙ‚Ø©)"

        # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        MeetingReport.objects.filter(meeting=meeting).delete()
        MeetingReport.objects.create(
            meeting=meeting,
            summary=summary.strip(),
            decisions="\n".join(decisions) or "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù‚Ø±Ø§Ø±Ø§Øª",
            action_items="\n".join(tasks) or "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù‡Ø§Ù…"
        )

        # 9. ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹
        meeting.processed = True
        meeting.save()

        print(f"\nâœ… Meeting processed successfully!")
        print(f"ğŸ“Š Summary:")
        print(f"   - Speakers identified: {len(speaker_stats)}")
        print(f"   - Total segments: {len(merged_segments)}")
        print(f"   - Decisions: {len(decisions)}")
        print(f"   - Tasks: {len(tasks)}")

        # 10. Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        print(f"\nğŸ“ Sample results:")
        print("-" * 60)

        for seg in TranscriptSegment.objects.filter(meeting=meeting)[:5]:
            print(f"\nğŸ¤ {seg.speaker.name} ({seg.start_time:.1f}s - {seg.end_time:.1f}s):")
            print(f"   \"{seg.text[:100]}...\"")
            if seg.is_decision:
                print("   âš¡ [Ù‚Ø±Ø§Ø±]")
            if seg.is_action_item:
                print("   ğŸ“Œ [Ù…Ù‡Ù…Ø©]")

        return True

    except Exception as e:
        logger.error(f"Error processing meeting: {str(e)}")
        print(f"\nâŒ Error: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


# ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
if __name__ == "__main__":
    import sys

    # ØªØ­Ù‚Ù‚ Ù…Ù† Hugging Face token
    if not os.getenv("HUGGINGFACE_TOKEN"):
        print("âŒ Error: HUGGINGFACE_TOKEN not found in environment!")
        print("Please add it to .env file")
        sys.exit(1)

    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ø¬ØªÙ…Ø§Ø¹
    if len(sys.argv) > 1:
        meeting_id = int(sys.argv[1])
        meeting = Meeting.objects.get(id=meeting_id)
    else:
        meeting = Meeting.objects.filter(processed=False).first()
        if not meeting:
            meeting = Meeting.objects.last()

    if meeting:
        print(f"\nğŸš€ Starting automatic voice comparison processing...")
        print("=" * 60)

        # Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø­Ø§Ù„Ø©
        meeting.processed = False
        meeting.save()

        # Ù…Ø¹Ø§Ù„Ø¬Ø©
        success = process_meeting_auto(meeting.id)

        if success:
            print("\nğŸ‰ Success! Check the results in the web interface.")
        else:
            print("\nğŸ˜ Processing failed. Check the logs.")
    else:
        print("âŒ No meetings found!")
        print("Upload a meeting first.")